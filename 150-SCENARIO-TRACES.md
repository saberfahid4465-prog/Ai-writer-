# AI Writer ‚Äî 150 Scenario Code Traces

**Date:** Phase 18  
**Scope:** 50 Generation + 50 Summarize + 50 Translation  
**Method:** Line-by-line code trace through actual source files  

---

## BUGS FOUND SUMMARY

| # | ID | Severity | File | Bug Description |
|---|-----|----------|------|-----------------|
| 1 | GEN-BUG-1 | **CRITICAL** | pdfGenerator.ts | `langNameToCode` missing 6 languages (Thai, Bengali, Hebrew, Greek, Vietnamese, Ukrainian) ‚Äî all non-Latin text rendered as `?????` |
| 2 | GEN-BUG-2 | **CRITICAL** | EditorScreen.tsx | `sections.indexOf(s)` always returns -1 ‚Äî slides state never used for PPT generation |
| 3 | GEN-BUG-3 | **HIGH** | pdfGenerator.ts | PDF section headings use `drawText(maxWidth)` which truncates ‚Äî not wrapped like paragraphs |
| 4 | GEN-BUG-4 | **HIGH** | pdfGenerator.ts | Very long PDF titles overflow above visible page area |
| 5 | GEN-BUG-5 | **MEDIUM** | pexelsService.ts | Stores original photo dimensions but downloads 'small' ‚Äî Word images blurry |
| 6 | GEN-BUG-6 | **MEDIUM** | EditorScreen.tsx | No validation if all sections cleared ‚Äî generates near-empty documents |
| 7 | GEN-BUG-7 | **MEDIUM** | pptGenerator.ts | Title/subtitle hardcoded `align:'left'` ignoring RTL languages |
| 8 | GEN-BUG-8 | **LOW** | pptGenerator.ts | "Thank You" end slide hardcoded in English ‚Äî not localized |
| 9 | GEN-BUG-9 | **LOW** | fontCacheService.ts | Inline `uint8ArrayToBase64` has incorrect padding ‚Äî cached fonts may have trailing zeros |
| 10 | SUM-BUG-1 | **MEDIUM** | SummarizeProcessingScreen | `wasTruncated` flag from fileParserService never shown to user |
| 11 | TRANS-BUG-1 | **MEDIUM** | TranslateProcessingScreen | Same `wasTruncated` flag issue ‚Äî user unaware of truncation |

---

## PART 1: GENERATION SCENARIOS (GEN-1 through GEN-50)

### GEN-1: Basic English topic, all 4 formats
**Input:** topic="Climate Change", language="English", formats=["pdf","docx","pptx","xlsx"]  
**Trace:**  
1. EditorScreen receives `aiOutput` with 3‚Äì5 sections, each having heading+paragraph+bullets  
2. `handleGenerateFiles()` ‚Üí `validSections` filters: all have heading.trim() && paragraph.trim() ‚Üí pass  
3. Bullets filtered, none empty ‚Üí bullets arrays unchanged  
4. `validSlides` mapping: `sections.indexOf(s)` ‚Üí **returns -1** (BUG GEN-BUG-2: `s` is a `.map()` clone, not original reference) ‚Üí fallback `{ title: s.heading, bullets: s.bullets, image_keyword: s.image_keyword }`  
5. `editedOutput` assembled. `clearImageCache()` called. Images fetched via Pexels.  
6. PDF: `hasNonLatinText("Climate Change...")` ‚Üí false ‚Üí Helvetica used. `sanitizeForWinAnsi` active. Title wrapped via `wrapText`. Sections rendered. Images embedded as JPEG.  
7. Word: `isRTL` = false (English not in rtlLanguages). Sections + images rendered normally.  
8. PPT: `isRTL` = false. Title slide + content slides + "Thank You" slide created.  
9. Excel: `sanitizeSheetName("Climate Change")` ‚Üí "Climate Change" (no illegal chars, 14 chars < 31). Data rows created. Images sheet if images exist.  
10. Files saved, history entry added, navigate to Result.  
**Result:** ‚úÖ Pass (BUG-2 has no visible effect since fallback reconstructs same data)

### GEN-2: Title with colon character ‚Üí Excel worksheet
**Input:** topic="Cristiano Ronaldo: A Legend of Modern Football", language="English"  
**Trace:**  
1. Title = "Cristiano Ronaldo: A Legend of Modern Football"  
2. Excel: `sanitizeSheetName("Cristiano Ronaldo: A Legend...")` ‚Üí `:` replaced with space ‚Üí "Cristiano Ronaldo  A Legend of Modern Football" ‚Üí whitespace collapsed ‚Üí "Cristiano Ronaldo A Legend of M" (31 chars)  
3. Worksheet created successfully  
**Result:** ‚úÖ Pass (FIXED in previous commit)

### GEN-3: Title with asterisk, question mark, brackets
**Input:** topic="What is AI? [A Complete Guide]*", language="English"  
**Trace:**  
1. `sanitizeSheetName("What is AI? [A Complete Guide]*")` ‚Üí `?`, `[`, `]`, `*` replaced with spaces ‚Üí "What is AI   A Complete Guide  " ‚Üí collapsed ‚Üí "What is AI A Complete Guide" (26 chars)  
**Result:** ‚úÖ Pass

### GEN-4: Title with backslash and forward slash
**Input:** topic="IT Security: Windows\\Linux/Mac Comparison", language="English"  
**Trace:**  
1. `sanitizeSheetName(...)` ‚Üí `:`, `\\`, `/` replaced ‚Üí "IT Security  Windows Linux Mac " ‚Üí collapsed ‚Üí "IT Security Windows Linux Mac C" (31 chars)  
**Result:** ‚úÖ Pass

### GEN-5: Very long title exceeds 31 chars for Excel
**Input:** topic="The Comprehensive Guide to Understanding Artificial Intelligence and Machine Learning in Modern Healthcare Systems"  
**Trace:**  
1. `sanitizeSheetName(longTitle)` ‚Üí no illegal chars ‚Üí `.substring(0, 31)` = "The Comprehensive Guide to Unde"  
**Result:** ‚úÖ Pass

### GEN-6: Empty title for Excel
**Input:** User clears title in editor to ""  
**Trace:**  
1. `sanitizeSheetName("")` ‚Üí `.replace(...)` ‚Üí `"".trim()` ‚Üí `""` ‚Üí `.substring(0,31)` ‚Üí `""` ‚Üí `|| 'Sheet'` ‚Üí "Sheet"  
**Result:** ‚úÖ Pass

### GEN-7: Arabic language ‚Äî PDF font loading
**Input:** topic="ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß", language="Arabic"  
**Trace:**  
1. PDF: `sampleText = "ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ..."` ‚Üí `hasNonLatinText()` ‚Üí Arabic chars > 0xFF ‚Üí `nonLatin/total > 0.2` ‚Üí true  
2. `langCode = "arabic"` ‚Üí `langNameToCode["arabic"]` = `'ar'` ‚Üí `getCachedFont('ar')` ‚Üí `getFontKey('ar')` ‚Üí `LANGUAGE_TO_FONT['ar']` = `'arabic'` ‚Üí `FONT_URLS['arabic']` exists ‚úì  
3. Custom font downloaded/cached ‚Üí `pdfDoc.embedFont(fontBytes, { subset: true })` ‚Üí success  
4. `useCustomFont = true` ‚Üí `safeText = (t) => t` (no sanitization)  
5. Title drawn with custom Arabic font ‚úì  
6. Word: `isRTL = true` (language "Arabic" includes 'arabic') ‚Üí bidirectional + rightToLeft flags set ‚úì  
7. PPT: `isRTL = true` ‚Üí `pptx.rtlMode = true` ‚úì BUT title `align: 'left'` hardcoded (BUG GEN-BUG-7)  
**Result:** ‚ö†Ô∏è PDF/Word OK. PPT title alignment wrong for RTL.

### GEN-8: Thai language ‚Äî PDF font loading  ‚Üê **CRITICAL BUG**
**Input:** topic="‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®", language="Thai"  
**Trace:**  
1. PDF: `sampleText` contains Thai chars ‚Üí `hasNonLatinText()` ‚Üí true  
2. `langCode = "thai"` ‚Üí `langNameToCode["thai"]` = **undefined** (NOT in the map!)  
3. `code = "thai".split(/[\s-]/)[0]` = `"thai"` ‚Üí `getCachedFont("thai")`  
4. `getFontKey("thai")` ‚Üí `LANGUAGE_TO_FONT["thai"]` = **undefined** ‚Üí returns `''`  
5. `fontBytes = null` ‚Üí falls back to Helvetica  
6. `useCustomFont = false` ‚Üí `safeText = sanitizeForWinAnsi`  
7. All Thai characters ‚Üí `sanitizeForWinAnsi` ‚Üí replaced with `?`  
8. **Title page shows: "????????????????????????????"**  
**Result:** ‚ùå **BUG GEN-BUG-1: Thai PDF completely broken ‚Äî all text is `?????`**

### GEN-9: Bengali language ‚Äî PDF font loading  ‚Üê **CRITICAL BUG**
**Input:** topic="‡¶ú‡¶≤‡¶¨‡¶æ‡¶Ø‡¶º‡ßÅ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶®", language="Bengali"  
**Trace:** Same flow as GEN-8. `langNameToCode["bengali"]` = undefined ‚Üí falls back to Helvetica ‚Üí `sanitizeForWinAnsi` ‚Üí all `?`  
**Result:** ‚ùå **BUG GEN-BUG-1: Bengali PDF completely broken**

### GEN-10: Hebrew language ‚Äî PDF font loading  ‚Üê **CRITICAL BUG**
**Input:** topic="◊©◊ô◊†◊ï◊ô◊ô ◊ê◊ß◊ú◊ô◊ù", language="Hebrew"  
**Trace:**  
1. `langNameToCode["hebrew"]` = **undefined** ‚Üí fallback to Helvetica  
2. Hebrew chars ‚Üí `sanitizeForWinAnsi` ‚Üí all `?`  
3. Additional issue: Word `isRTL` check: `rtlLanguages.some(lang => "hebrew".includes(lang))` ‚Üí 'hebrew' is IN rtlLanguages ‚Üí `isRTL = true` ‚úì  
4. PPT: 'hebrew' is in rtlLanguages ‚Üí `isRTL = true` ‚úì but alignment hardcoded  
**Result:** ‚ùå **BUG GEN-BUG-1: Hebrew PDF completely broken**

### GEN-11: Vietnamese language ‚Äî PDF font loading
**Input:** topic="Bi·∫øn ƒë·ªïi kh√≠ h·∫≠u", language="Vietnamese"  
**Trace:**  
1. `hasNonLatinText("Bi·∫øn ƒë·ªïi...")` ‚Üí Vietnamese diacritical chars (·∫ø, ·ªï, etc.) have codes 0x1EBF, 0x1ED5 etc. which are > 0xFF  
2. `nonLatin/total` check: out of ~18 chars, ~4 have codes > 0xFF ‚Üí 4/18 = 0.22 > 0.2 ‚Üí **true** (enters custom font branch)  
3. `langNameToCode["vietnamese"]` = **undefined** ‚Üí code = "vietnamese"  
4. `getCachedFont("vietnamese")` ‚Üí `LANGUAGE_TO_FONT["vietnamese"]` = undefined ‚Üí null  
5. Falls back to Helvetica. `sanitizeForWinAnsi` replaces ·∫ø, ·ªï with `?`  
6. **BUT: Most Vietnamese chars ARE in CP-1252 (Latin Supplement 0xA0-0xFF)**. Only the combining chars are not.  
**Result:** ‚ùå **BUG GEN-BUG-1: Vietnamese PDF partially broken ‚Äî diacritical chars replaced with `?`**

### GEN-12: Greek language ‚Äî PDF font loading
**Input:** topic="ŒöŒªŒπŒºŒ±œÑŒπŒ∫ŒÆ Œ±ŒªŒªŒ±Œ≥ŒÆ", language="Greek"  
**Trace:** `langNameToCode["greek"]` = undefined ‚Üí code = "greek" ‚Üí font not found. Greek chars (0x0391-0x03CE) ‚Üí `sanitizeForWinAnsi` ‚Üí `?`. **All Greek text becomes `?`.**  
**Result:** ‚ùå **BUG GEN-BUG-1: Greek PDF completely broken**

### GEN-13: Ukrainian language ‚Äî PDF font loading
**Input:** topic="–ó–º—ñ–Ω–∏ –∫–ª—ñ–º–∞—Ç—É", language="Ukrainian"  
**Trace:** `langNameToCode["ukrainian"]` = undefined. Ukrainian Cyrillic chars ‚Üí `sanitizeForWinAnsi` ‚Üí `?`. All text becomes `?????`.  
**Result:** ‚ùå **BUG GEN-BUG-1: Ukrainian PDF completely broken**

### GEN-14: Chinese language ‚Äî PDF font loading (should work)
**Input:** topic="Ê∞îÂÄôÂèòÂåñ", language="Chinese"  
**Trace:**  
1. `langNameToCode["chinese"]` = `'zh'` ‚úì  
2. `getCachedFont('zh')` ‚Üí `LANGUAGE_TO_FONT['zh']` = `'chinese'` ‚Üí `FONT_URLS['chinese']` exists  
3. Custom font loaded. CJK wrapping via `wrapTextCJK`. Title renders correctly.  
**Result:** ‚úÖ Pass

### GEN-15: Japanese language ‚Äî PDF font (should work)
**Input:** topic="Ê∞óÂÄôÂ§âÂãï", language="Japanese"  
**Trace:** `langNameToCode["japanese"]` = `'ja'` ‚Üí font loaded ‚úì. CJK wrapping ‚úì.  
**Result:** ‚úÖ Pass

### GEN-16: Korean language ‚Äî PDF font (should work)
**Input:** topic="Í∏∞ÌõÑ Î≥ÄÌôî", language="Korean"  
**Trace:** `langNameToCode["korean"]` = `'ko'` ‚Üí font loaded ‚úì.  
**Result:** ‚úÖ Pass

### GEN-17: Hindi language ‚Äî PDF font (should work)
**Input:** topic="‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§®", language="Hindi"  
**Trace:** `langNameToCode["hindi"]` = `'hi'` ‚Üí `LANGUAGE_TO_FONT['hi']` = `'devanagari'` ‚Üí font loaded ‚úì.  
**Result:** ‚úÖ Pass

### GEN-18: Russian language ‚Äî PDF font
**Input:** topic="–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–ª–∏–º–∞—Ç–∞", language="Russian"  
**Trace:**  
1. `langNameToCode["russian"]` = `'ru'` ‚úì  
2. `LANGUAGE_TO_FONT['ru']` = `'latin'` ‚Üí Noto Sans Latin (includes Cyrillic) ‚Üí font loaded  
3. Custom font renders Russian correctly ‚úì  
**Result:** ‚úÖ Pass

### GEN-19: Turkish language ‚Äî PDF font
**Input:** topic="ƒ∞klim Deƒüi≈üikliƒüi", language="Turkish"  
**Trace:** `langNameToCode["turkish"]` = `'tr'` ‚Üí `LANGUAGE_TO_FONT['tr']` = `'turkish'` ‚Üí same Noto Sans Latin URL ‚Üí ‚úì.  
Special chars: ƒ∞ (0x0130), ƒ± (0x0131), ƒü (0x011F), ≈ü (0x015F). ƒ∞ is > 0xFF ‚Üí flagged non-Latin.  
Custom font handles these ‚úì.  
**Result:** ‚úÖ Pass

### GEN-20: Persian/Farsi language ‚Äî PDF font
**Input:** topic="ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿ¢ÿ® Ÿà ŸáŸàÿß€å€å", language="Persian"  
**Trace:** `langNameToCode["persian"]` = `'fa'` ‚Üí `'persian'` font (same as Arabic) ‚Üí ‚úì.  
Word: `isRTL` check for 'persian' ‚Üí yes ‚úì. PPT: 'persian' ‚Üí yes ‚úì.  
**Result:** ‚úÖ Pass (same alignment issue as Arabic)

### GEN-21: Section with very long heading ‚Äî PDF truncation ‚Üê **BUG**
**Input:** Section heading = "The Comprehensive Analysis of Global Climate Change Impacts on Agricultural Production Systems and Food Security in Developing Nations"  
**Trace:**  
1. PDF rendering: `currentPage.drawText(safeText(section.heading), { ..., maxWidth: CONTENT_WIDTH })`  
2. pdf-lib `drawText` with `maxWidth` **truncates** text that exceeds width ‚Äî does NOT wrap  
3. At 18pt with Helvetica, this 138-char heading exceeds CONTENT_WIDTH (451.28pt)  
4. Text truncated mid-word, no continuation on next line  
5. Compare: paragraph text uses `wrapText()` which manually wraps ‚Üí fully visible  
**Result:** ‚ùå **BUG GEN-BUG-3: PDF headings truncated, not wrapped**

### GEN-22: Very long title (15+ words) ‚Äî PDF title page overflow ‚Üê **BUG**
**Input:** title = "A Comprehensive Study on the Environmental Social and Economic Impacts of Climate Change on Small Island Developing States in the Pacific Ocean"  
**Trace:**  
1. `wrapText(title, fontBold, 28, CONTENT_WIDTH)` ‚Üí wraps into ~6 lines  
2. `titleLineHeight = 28 * 1.5 = 42pt`  
3. `totalTitleHeight = 6 * 42 = 252pt`  
4. `titleY = 841.89/2 + 252/2 = 420.9 + 126 = 546.9pt` ‚Üí first line at 546.9  
5. Last line at `546.9 - 5*42 = 336.9` ‚Üí still within page ‚úì  
6. BUT with 12+ lines: `totalTitleHeight = 12 * 42 = 504`. `titleY = 420.9 + 252 = 672.9` ‚Üí still OK  
7. With 20+ lines (extreme): `totalTitleHeight = 840`. `titleY = 420.9 + 420 = 840.9` ‚Üí **first line AT page top boundary**  
8. With 21+ lines: **titleY > PAGE_HEIGHT** ‚Üí text drawn above visible area  
**Result:** ‚ùå **BUG GEN-BUG-4: Extreme title lengths overflow above page** (rare but possible)

### GEN-23: All sections have empty headings ‚Äî user deletes all headings
**Input:** User edits all section headings to "" (empty), paragraphs still have content  
**Trace:**  
1. `validSections = sections.filter(s => s.heading.trim() && s.paragraph.trim())`  
2. `"".trim()` ‚Üí `""` ‚Üí falsy ‚Üí ALL sections filtered out  
3. `validSections = []`  
4. `validSlides = [].map(...)` ‚Üí `[]`  
5. `editedOutput.pdf_word.sections = []`  
6. PDF: title page only, no content pages  
7. Word: title + author + language only  
8. PPT: title slide + "Thank You" only  
9. Excel: `rows = []` (headers but no data)  
10. Files generated and saved (almost empty). History entry added.  
11. User sees 4 files but they contain no real content.  
**Result:** ‚ùå **BUG GEN-BUG-6: No validation ‚Äî empty documents generated silently**

### GEN-24: All sections have empty paragraphs
**Input:** User clears all paragraphs but keeps headings  
**Trace:** Same as GEN-23 ‚Äî `paragraph.trim()` is falsy ‚Üí all filtered out ‚Üí empty documents  
**Result:** ‚ùå **BUG GEN-BUG-6 (same)**

### GEN-25: One valid section + one empty section
**Input:** Section 1: heading="A", paragraph="Text". Section 2: heading="B", paragraph=""  
**Trace:**  
1. `validSections` filters: Section 1 passes, Section 2 filtered out  
2. Only Section 1 appears in all outputs  
3. `validSlides` maps 1 section ‚Üí 1 slide  
**Result:** ‚úÖ Pass (partial content works correctly)

### GEN-26: Section with empty bullets array
**Input:** Section has heading+paragraph but bullets=[] (user removed all bullets)  
**Trace:**  
1. After filter: section passes (heading+paragraph present)  
2. `.map(s => ({ ...s, bullets: s.bullets.filter(b => b.trim()) }))` ‚Üí bullets = []  
3. `.map(s => (s.bullets.length === 0 ? { ...s, bullets: [s.heading] } : s))` ‚Üí bullets = [heading]  
4. Fallback bullet is the heading text ‚Üí appears as bullet in all formats  
**Result:** ‚úÖ Pass (graceful fallback)

### GEN-27: Section with whitespace-only bullets
**Input:** bullets=["  ", "\t", "\n"]  
**Trace:**  
1. `bullets.filter(b => b.trim())` ‚Üí "  ".trim()="" ‚Üí falsy ‚Üí filtered. All 3 filtered out.  
2. `bullets = []` ‚Üí fallback to `[s.heading]`  
**Result:** ‚úÖ Pass

### GEN-28: PDF image embedding ‚Äî non-JPEG image data
**Input:** Pexels returns a PNG (rare but possible if CDN serves wrong format)  
**Trace:**  
1. `pdfDoc.embedJpg(img.imageBytes)` ‚Üí pdf-lib checks JPEG magic bytes (0xFFD8)  
2. If not JPEG ‚Üí throws Error  
3. Caught by try-catch: `console.warn('Failed to embed image in PDF:', e)` ‚Üí image skipped  
4. PDF continues without image  
**Result:** ‚úÖ Pass (graceful degradation)

### GEN-29: PDF image embedding ‚Äî corrupt image bytes
**Input:** Network error mid-download ‚Üí partial imageBytes  
**Trace:**  
1. `downloadImage()` ‚Äî if response completes but content is partial, `response.arrayBuffer()` returns partial data  
2. `new Uint8Array(arrayBuffer)` ‚Üí valid but truncated  
3. PDF: `embedJpg(truncatedBytes)` ‚Üí likely throws (invalid JPEG structure)  
4. Caught by try-catch ‚Üí image skipped  
**Result:** ‚úÖ Pass

### GEN-30: Word image embedding ‚Äî very large image
**Input:** Pexels returns 5000√ó3000 photo (original dimensions), small download at 300√ó200  
**Trace:**  
1. `img.width = 5000`, `img.height = 3000` (from PexelsPhoto, NOT from small image)  
2. Word: `scale = Math.min(460/5000, 280/3000, 1) = Math.min(0.092, 0.093, 1) = 0.092`  
3. `displayWidth = 460`, `displayHeight = 277`  
4. Image displayed at 460√ó277 in Word doc, but actual pixels are ~300√ó200  
5. **Image looks blurry/pixelated** when opened in Word  
**Result:** ‚ö†Ô∏è **BUG GEN-BUG-5: Image quality degraded ‚Äî original dimensions used for scaling but small image downloaded**

### GEN-31: Excel image embedding
**Input:** Images Map has 3 entries  
**Trace:**  
1. `images.size > 0` ‚Üí true ‚Üí creates 'Images' sheet  
2. Hardcoded sheet name `'Images'` ‚Äî no sanitization needed (safe name) ‚úì  
3. For each image: `uint8ArrayToBase64(img.imageBytes)` ‚Üí base64 string  
4. `workbook.addImage({base64: imgBase64, extension: 'jpeg'})` ‚Üí image ID  
5. `imgSheet.addImage(imageId, {tl: {col:2, row: imgRowNum-1}, ext: {width:250, height:150}})` ‚Üí image placed  
6. Fixed dimensions 250√ó150 regardless of original ‚Üí OK for thumbnails  
**Result:** ‚úÖ Pass

### GEN-32: PPT image embedding ‚Äî base64 format
**Input:** slideImage with imageBytes  
**Trace:**  
1. `uint8ArrayToBase64(slideImage.imageBytes)` ‚Üí base64 string  
2. `data: \`image/jpeg;base64,${imgBase64}\``  
3. pptxgenjs splits on comma: `['image/jpeg;base64', base64Data]`  
4. Extracts type: `'image/jpeg;base64'.split(':')[1]` ‚Üí undefined ‚Üí fallback: `'image/jpeg;base64'.split(';')[0]` ‚Üí `'image/jpeg'` ‚úì  
5. Image embedded correctly  
**Result:** ‚úÖ Pass

### GEN-33: PPT RTL text alignment ‚Üê **BUG**
**Input:** language="Arabic"  
**Trace:**  
1. `isRTL = true` ‚Üí `pptx.rtlMode = true`  
2. Title slide: `align: 'left'` (hardcoded) ‚Äî **should be 'right'** for Arabic  
3. Subtitle: `align: 'left'` (hardcoded) ‚Äî same issue  
4. Content slides: bullet text inherits from pptx.rtlMode which may or may not override align  
5. End slide "Thank You": `align: 'center'` ‚Äî OK for centered text  
**Result:** ‚ùå **BUG GEN-BUG-7: Arabic PPT title left-aligned instead of right-aligned**

### GEN-34: PPT end slide in Japanese
**Input:** language="Japanese"  
**Trace:**  
1. End slide shows `"Thank You"` and `"Generated by AI Writer"` ‚Äî both in English  
2. For a Japanese presentation, this is inconsistent  
**Result:** ‚ö†Ô∏è **BUG GEN-BUG-8: End slide not localized**

### GEN-35: Unicode filename generation
**Input:** topic="Ê∞óÂÄôÂ§âÂãï„É¨„Éù„Éº„Éà" (Japanese)  
**Trace:**  
1. `sanitizeTopic("Ê∞óÂÄôÂ§âÂãï„É¨„Éù„Éº„Éà")` ‚Üí regex `/[^\p{L}\p{N}\s]/gu` keeps all CJK letters  
2. ‚Üí "Ê∞óÂÄôÂ§âÂãï„É¨„Éù„Éº„Éà" ‚Üí `.replace(/\s+/g, '_')` ‚Üí "Ê∞óÂÄôÂ§âÂãï„É¨„Éù„Éº„Éà" (no spaces) ‚Üí `substring(0,40)`  
3. `generateFileName(topic, 'pdf')` = `"Ê∞óÂÄôÂ§âÂãï„É¨„Éù„Éº„Éà_20260214120000.pdf"`  
4. `saveFile(name, data)` ‚Üí `FileSystem.writeAsStringAsync(OUTPUT_DIR + name, ...)` ‚Äî Expo handles Unicode paths ‚úì  
**Result:** ‚úÖ Pass

### GEN-36: Topic with only special characters
**Input:** topic="!!!@@@###$$$"  
**Trace:**  
1. `sanitizeTopic("!!!@@@###$$$")` ‚Üí regex removes all ‚Üí `""` ‚Üí fallback `"ai_writer_doc"`  
2. `generateFileName` = `"ai_writer_doc_20260214120000.pdf"` ‚úì  
**Result:** ‚úÖ Pass

### GEN-37: Parallel file generation ‚Äî one format fails
**Input:** PDF generation throws (e.g., font download timeout), Word/PPT/Excel succeed  
**Trace:**  
1. `filePromises` has 4 promises  
2. PDF throws ‚Üí `Promise.all` rejects with PDF error  
3. At rejection, `files[]` may contain 0-3 entries (whichever completed first)  
4. Catch block: `for (const f of files) { FileSystem.deleteAsync(f.path) }` ‚Äî partial files cleaned up ‚úì  
5. User sees error Alert, no orphan files  
**Result:** ‚úÖ Pass (cleanup works correctly)

### GEN-38: Parallel file generation ‚Äî all succeed
**Input:** Normal case, all 4 formats  
**Trace:**  
1. All 4 promises push to `files[]`  
2. `files.push()` is synchronous in JS event loop ‚Äî no race condition  
3. `addHistoryEntry()` saves 4 files  
4. Navigate to Result with all files  
**Result:** ‚úÖ Pass

### GEN-39: addHistoryEntry with 50+ existing entries
**Input:** History already has 50 entries  
**Trace:**  
1. `history.unshift(newEntry)` ‚Üí 51 entries  
2. `trimmed = history.slice(0, 50)` ‚Üí keeps newest 50  
3. `removed = history.slice(50)` ‚Üí 1 old entry  
4. Old entry's files deleted from disk  
5. `AsyncStorage.setItem(HISTORY_KEY, JSON.stringify(trimmed))` ‚Äî saves 50 entries  
**Result:** ‚úÖ Pass

### GEN-40: Font download timeout (15s)
**Input:** Slow network, Thai font download takes >15s  
**Trace:**  
1. `getCachedFont` ‚Üí `setTimeout(() => controller.abort(), 15000)`  
2. After 15s ‚Üí `controller.abort()` ‚Üí fetch throws AbortError  
3. `catch (error)` ‚Üí `console.warn('Font cache error:')` ‚Üí returns `null`  
4. PDF falls back to Helvetica  
5. For Thai: text becomes `?????` (same result as BUG GEN-BUG-1 but for different reason)  
**Result:** ‚ö†Ô∏è Expected fallback behavior (but Thai still broken due to BUG-1)

### GEN-41: Font cached from previous generation
**Input:** Second generation with Arabic language  
**Trace:**  
1. `getCachedFont('ar')` ‚Üí `getFontKey('ar')` = `'arabic'`  
2. `cacheFile = FONT_CACHE_DIR + 'arabic.ttf'`  
3. `getInfoAsync(cacheFile)` ‚Üí `exists: true` (cached from first run)  
4. `readAsStringAsync(cacheFile, Base64)` ‚Üí `base64ToUint8Array(base64)` ‚Üí font bytes  
5. Font embedded from cache ‚Äî no network request needed  
**Result:** ‚úÖ Pass (caching works)

### GEN-42: fontCacheService base64 encoding ‚Äî 1-byte remainder ‚Üê **BUG**
**Input:** Font file with `bytes.length % 3 === 1` (e.g., 100 bytes)  
**Trace (inline uint8ArrayToBase64 in fontCacheService):**  
1. Processing last triplet: `i` points to last byte  
2. `a = binary.charCodeAt(i++)` ‚Üí reads byte 99, i=100  
3. `b = i < binary.length ? ...` ‚Üí `100 < 100` ‚Üí false ‚Üí `b = 0`  
4. `c = i < binary.length ? ...` ‚Üí false ‚Üí `c = 0`  
5. `bitsCount = i <= binary.length + 1 ? (i <= binary.length ? 3 : 2) : 1`  
6. `100 <= 101` ‚Üí true. `100 <= 100` ‚Üí true. `bitsCount = 3` ‚Üê **WRONG!** Only 1 byte read  
7. All 4 chars written (no `=` padding) instead of 2 chars + `==`  
8. Decoder reads back: `padding = 0` (no `=` at end) ‚Üí `byteLength` too large ‚Üí extra zero bytes  
**Result:** ‚ùå **BUG GEN-BUG-9: Incorrect base64 padding ‚Äî cached fonts have trailing zero bytes**

### GEN-43: Image fetch fails entirely
**Input:** Pexels API is down (returns 500 for all requests)  
**Trace:**  
1. `fetchImagesForKeywords(keywords)` ‚Üí each `fetchImageForKeyword` ‚Üí `searchPhoto` ‚Üí response.ok = false  
2. Returns `null` for each ‚Üí `results` Map is empty  
3. `imageMap.size === 0`  
4. All generators skip image embedding (check `if (images && section.image_keyword)` ‚Üí images is empty Map ‚Üí `images.get(keyword)` returns `undefined` ‚Üí skipped)  
**Result:** ‚úÖ Pass (graceful degradation without images)

### GEN-44: Image fetch partial success
**Input:** 3 sections with keywords, Pexels returns images for 2 out of 3  
**Trace:**  
1. `fetchImagesForKeywords(['nature', 'technology', 'medicine'])` ‚Üí parallel fetch  
2. 'medicine' fetch fails ‚Üí `null` ‚Üí not added to Map  
3. `imageMap` has 2 entries  
4. Generators: sections with 'nature' and 'technology' get images, 'medicine' section has no image  
5. No crash, no error  
**Result:** ‚úÖ Pass

### GEN-45: Empty image keyword
**Input:** AI returns section with `image_keyword: ""`  
**Trace:**  
1. `extractImageKeywords` ‚Üí `"".trim().length > 0` ‚Üí false ‚Üí keyword not added  
2. No Pexels fetch for empty keyword  
3. Generator: `images.get("")` ‚Üí undefined ‚Üí no image embedded  
**Result:** ‚úÖ Pass

### GEN-46: Duplicate image keywords across sections
**Input:** 3 sections all with `image_keyword: "nature"`  
**Trace:**  
1. `extractImageKeywords` returns `['nature', 'nature', 'nature']`  
2. `fetchImagesForKeywords` deduplicates: `[...new Set(...)]` = `['nature']`  
3. Single Pexels fetch for 'nature'  
4. Result cached: `imageCache.set('nature', docImage)`  
5. All 3 sections get the same image from Map  
**Result:** ‚úÖ Pass

### GEN-47: Special characters in bullet text ‚Äî Word RTL
**Input:** language="Arabic", bullet text="‚Ä¢ ŸÜŸÇÿ∑ÿ© ŸÖŸáŸÖÿ©: ÿßŸÑÿ™ÿ∫ŸäŸäÿ± ÿ∂ÿ±Ÿàÿ±Ÿä!"  
**Trace:**  
1. Word: `TextRun({ text: bullet, rightToLeft: true })` ‚úì  
2. Arabic text with `:` and `!` ‚Äî both valid in text content  
3. docx library handles UTF-8 ‚úì  
**Result:** ‚úÖ Pass

### GEN-48: PDF bullet with very long text (500+ chars)
**Input:** Single bullet with 500 characters  
**Trace:**  
1. PDF: `bulletText = "  ‚Ä¢  " + bullet` ‚Üí 505 chars  
2. `wrapText(bulletText, fontRegular, 11, CONTENT_WIDTH - 20, safeText)` ‚Üí wraps to ~25 lines  
3. Each line: checks `yPos < MARGIN + 20` ‚Üí if page boundary reached, new page added  
4. Bullet renders across multiple lines, possibly multiple pages  
**Result:** ‚úÖ Pass

### GEN-49: Single section with 1 bullet ‚Äî minimum content
**Input:** 1 section, heading="Test", paragraph="Hello world.", bullets=["Point"]  
**Trace:**  
1. `validSections`: heading.trim() ‚úì, paragraph.trim() ‚úì ‚Üí passes  
2. `bullets.filter(b => b.trim())` ‚Üí ["Point"] (1 bullet) ‚Üí `bullets.length > 0` ‚Üí no fallback  
3. All generators render 1 section with 1 bullet  
4. PPT: 1 content slide with 1 bullet  
5. Excel: 1 data row  
**Result:** ‚úÖ Pass

### GEN-50: Sections reordered then generated ‚Äî slide index mismatch
**Input:** User moves Section 2 to position 1, then generates  
**Trace:**  
1. `moveSection(1, 'up')` ‚Üí swaps `sections[0]` and `sections[1]`; also swaps `slides[0]` and `slides[1]`  
2. Both arrays stay in sync ‚úì  
3. `handleGenerateFiles()`:  
   a. `validSections` maps sections (new objects after .filter/.map)  
   b. `sections.indexOf(s)` ‚Üí **-1** (BUG GEN-BUG-2)  
   c. Fallback reconstructs slides from section data ‚Üí correct order since sections are already reordered  
4. PPT slides match reordered sections ‚úì (by coincidence, not by correct logic)  
**Result:** ‚ö†Ô∏è Works by coincidence due to BUG-2 fallback ‚Äî but logically broken

---

## PART 2: SUMMARIZE SCENARIOS (SUM-1 through SUM-50)

### SUM-1: Basic DOCX file upload ‚Äî happy path
**Input:** Upload "report.docx" (5KB), language="English"  
**Trace:**  
1. SummarizeScreen: `DocumentPicker.getDocumentAsync()` ‚Üí user picks file  
2. `setUploadedFile(result)` ‚Üí state updated  
3. User taps "Summarize AI" ‚Üí `handleSummarize()`  
4. Navigates to SummarizeProcessing with: uri, name="report.docx", language="English"  
5. `runSummarization()`:  
   a. Step 0: `parseUploadedFile(uri, "report.docx")` ‚Üí `getFileType` = 'docx'  
   b. `readAsStringAsync(uri, Base64)` ‚Üí base64 data  
   c. `parseDocx(base64)` ‚Üí JSZip.loadAsync ‚Üí find word/document.xml ‚Üí stripXml ‚Üí text  
   d. Content length > 2 chars ‚úì. Content < 15000 ‚Üí no truncation.  
   e. Step 1: `canMakeRequest()` ‚Üí true ‚úì  
   f. Step 2: `summarizeDocument(content, "English", "report.docx")` ‚Üí builds prompt ‚Üí API call  
   g. API returns JSON ‚Üí `parseAIResponse` validates ‚Üí AIWriterOutput  
   h. Step 3: `navigation.replace('Editor', {...})`  
6. EditorScreen opens with summarized content for editing  
**Result:** ‚úÖ Pass

### SUM-2: TXT file upload
**Input:** Upload "notes.txt" (2KB), language="Spanish"  
**Trace:**  
1. `getFileType("notes.txt")` = 'txt'  
2. `readAsStringAsync(uri, UTF8)` ‚Üí raw text  
3. Content validated, not truncated  
4. AI summarizes in Spanish  
**Result:** ‚úÖ Pass

### SUM-3: XLSX file upload
**Input:** Upload "data.xlsx" (10KB), language="English"  
**Trace:**  
1. `getFileType("data.xlsx")` = 'xlsx'  
2. `readAsStringAsync(uri, Base64)` ‚Üí `parseXlsx(base64)`  
3. JSZip extracts xl/sharedStrings.xml + xl/worksheets/sheet1.xml  
4. Shared strings parsed, cell values extracted, rows joined with ` | `  
5. Content = "[Sheet 1]\nHeader1 | Header2\nRow1Val | Row2Val..."  
6. AI summarizes the tabular data  
**Result:** ‚úÖ Pass

### SUM-4: PPTX file upload
**Input:** Upload "presentation.pptx" (50KB), language="French"  
**Trace:**  
1. `getFileType("presentation.pptx")` = 'pptx'  
2. `parsePptx(base64)` ‚Üí JSZip finds ppt/slides/slide*.xml files  
3. Slides sorted numerically. stripXml extracts text from each.  
4. Content = "[Slide 1]\nTitle Text\n[Slide 2]\n..." + speaker notes  
5. AI summarizes in French  
**Result:** ‚úÖ Pass

### SUM-5: PDF file upload ‚Äî should error
**Input:** Upload "document.pdf"  
**Trace:**  
1. DocumentPicker MIME types don't include 'application/pdf' ‚úì ‚Äî PDF cannot be selected from picker  
2. On some Android devices with poor MIME filtering, a PDF might slip through  
3. `getFileType("document.pdf")` = 'pdf'  
4. In `parseUploadedFile`: `if (fileType === 'pdf') throw new Error('PDF text extraction is not supported...')`  
5. Error caught by SummarizeProcessingScreen try-catch ‚Üí Alert shown  
**Result:** ‚úÖ Pass (graceful error for edge case)

### SUM-6: Large file ‚Äî content truncation ‚Üê **BUG**
**Input:** Upload "large_report.docx" with 30,000 characters of text  
**Trace:**  
1. `parseDocx` extracts full text (30,000 chars)  
2. `content.length > MAX_CHARS (15000)` ‚Üí `content = content.substring(0, 15000) + '\n\n[Content truncated...]'`  
3. `wasTruncated = true`  
4. Returns `{content, wasTruncated: true, ...}`  
5. SummarizeProcessingScreen: `const parsed = await parseUploadedFile(...)`  
6. Uses `parsed.content` (truncated to 15K)  
7. **Never checks `parsed.wasTruncated`** ‚Äî user has no idea half the document was cut off  
8. AI summarizes only the first half of the document  
**Result:** ‚ùå **BUG SUM-BUG-1: Truncation not communicated to user**

### SUM-7: Empty file upload
**Input:** Upload "empty.txt" (0 bytes)  
**Trace:**  
1. `readAsStringAsync(uri, UTF8)` ‚Üí `""`  
2. `content.trim().length < 2` ‚Üí `throw new Error('File "empty.txt" (0 B) has no extractable text...')`  
3. Error caught by SummarizeProcessingScreen ‚Üí Alert shown with message  
**Result:** ‚úÖ Pass

### SUM-8: Corrupt DOCX file
**Input:** Upload "corrupt.docx" (file is actually a renamed JPEG)  
**Trace:**  
1. `getFileType("corrupt.docx")` = 'docx'  
2. `readAsStringAsync(uri, Base64)` ‚Üí base64 of JPEG data  
3. `parseDocx(base64)` ‚Üí `JSZip.loadAsync(base64ToUint8Array(base64))` ‚Üí throws "Is not a valid zip file"  
4. Caught by outer try-catch in `parseUploadedFile`:  
   `throw new Error('Unable to read "corrupt.docx": Is not a valid zip file. The file may be corrupted or in an unsupported format.')`  
5. SummarizeProcessingScreen catches ‚Üí Alert shown  
**Result:** ‚úÖ Pass

### SUM-9: DOCX with no word/document.xml
**Input:** Upload modified DOCX with document.xml deleted  
**Trace:**  
1. JSZip opens successfully (it's a valid ZIP)  
2. `zip.file('word/document.xml')` ‚Üí null  
3. `throw new Error('Invalid DOCX: word/document.xml not found')`  
4. Caught and shown as alert  
**Result:** ‚úÖ Pass

### SUM-10: PPTX with no slides
**Input:** Upload PPTX with all slides deleted (empty presentation)  
**Trace:**  
1. `Object.keys(zip.files).filter(...)` ‚Üí no files matching `ppt/slides/slide*.xml`  
2. `slideFiles.length === 0` ‚Üí `throw new Error('Invalid PPTX: no slides found')`  
3. Caught and alerted  
**Result:** ‚úÖ Pass

### SUM-11: XLSX with no shared strings or worksheets
**Input:** Upload minimal XLSX with only empty sheets  
**Trace:**  
1. `ssFile = zip.file('xl/sharedStrings.xml')` ‚Üí null ‚Üí `sharedStrings = []`  
2. Sheet files found but rows have no `<c>` cells ‚Üí `rows = []` for each  
3. `sheetTexts.length === 0` ‚Üí falls back to `sharedStrings.join('\n')` ‚Üí `""`  
4. Content = "" ‚Üí `content.trim().length < 2` ‚Üí throws empty file error  
**Result:** ‚úÖ Pass

### SUM-12: File with XML entities in content
**Input:** DOCX containing `&amp;`, `&lt;`, `&gt;`, `&quot;`, `&apos;`  
**Trace:**  
1. `stripXml(docXml)` ‚Üí replaces `&amp;` ‚Üí `&`, `&lt;` ‚Üí `<`, etc.  
2. Clean text extracted correctly  
**Result:** ‚úÖ Pass

### SUM-13: File with numeric XML entities
**Input:** DOCX containing `&#169;` (¬©), `&#8212;` (‚Äî)  
**Trace:**  
1. `stripXml` ‚Üí `&#(\d+);` ‚Üí `String.fromCharCode(parseInt('169', 10))` ‚Üí ¬©  
2. `String.fromCharCode(8212)` ‚Üí ‚Äî (em dash)  
3. Characters preserved correctly  
**Result:** ‚úÖ Pass

### SUM-14: DOCX with headers and footers
**Input:** DOCX containing header "Company Name" and footer "Page 1"  
**Trace:**  
1. `parseDocx`: main document.xml parsed  
2. Loop: finds `word/header1.xml`, `word/footer1.xml`  
3. Each extracted via `stripXml`, filtered (length > 5)  
4. Appended as `"\n\n--- Headers/Footers ---\nCompany Name\nPage 1"`  
5. AI receives full text including headers/footers  
**Result:** ‚úÖ Pass

### SUM-15: PPTX with speaker notes
**Input:** PPTX with 3 slides and speaker notes on slide 2  
**Trace:**  
1. Slides parsed: `[Slide 1]`, `[Slide 2]`, `[Slide 3]`  
2. `ppt/notesSlides/notesSlide2.xml` found ‚Üí text extracted ‚Üí `[Speaker Notes]\n...`  
3. All content sent to AI  
**Result:** ‚úÖ Pass

### SUM-16: Token limit exceeded before summarization
**Input:** User has 0 remaining tokens  
**Trace:**  
1. Step 0: File parsed successfully  
2. Step 1: `canMakeRequest()` ‚Üí returns false  
3. `getRemainingTokens()` ‚Üí 0  
4. Alert: "Daily token limit reached (5,000 tokens/day). You have 0 tokens remaining."  
5. Button: "Go Back" ‚Üí navigates back  
**Result:** ‚úÖ Pass

### SUM-17: Token limit exceeded during API call
**Input:** Processing screen checks tokens ‚Üí OK. `callLongcatAPI` checks again ‚Üí fails  
**Trace:**  
1. SummarizeProcessingScreen: `canMakeRequest()` ‚Üí true (edge case: tokens very close to limit)  
2. `summarizeDocument` ‚Üí `callLongcatAPI` ‚Üí `canMakeRequest()` ‚Üí false (consumed by another flow)  
3. Throws "Daily token limit reached" error  
4. Error has no retry (contains 'Daily token limit') ‚Üí propagates to catch block  
5. Alert: "Summarization Failed" with "Try Again" and "Go Back"  
6. "Try Again" would hit same limit ‚Üí **endless fail loop until midnight**  
**Result:** ‚ö†Ô∏è UX issue but not crash

### SUM-18: AI returns invalid JSON
**Input:** API returns malformed response  
**Trace:**  
1. `callLongcatAPI` ‚Üí `response.json()` ‚Üí `data.choices[0].message.content = "I can't do that"`  
2. `parseAIResponse("I can't do that")` ‚Üí `JSON.parse(...)` ‚Üí throws SyntaxError  
3. `throw new Error('Invalid JSON from AI: ...')`  
4. `callLongcatAPI` retries (attempt 2): if same issue ‚Üí retries again  
5. After MAX_RETRIES=2, throws `"Failed to generate content after 2 attempts"`  
6. SummarizeProcessingScreen catches ‚Üí Alert with "Try Again" / "Go Back"  
**Result:** ‚úÖ Pass (retry + error handling works)

### SUM-19: AI returns JSON missing pdf_word
**Input:** API returns `{"ppt": {...}, "excel": {...}}`  
**Trace:**  
1. `parseAIResponse` ‚Üí `validatePdfWord(obj.pdf_word)` ‚Üí `obj.pdf_word` is undefined  
2. `throw new Error('Missing or invalid "pdf_word" in AI response')`  
3. Retry ‚Üí same response ‚Üí fails after 2 attempts  
**Result:** ‚úÖ Pass

### SUM-20: AI returns empty sections array
**Input:** API returns `{"pdf_word": {"title": "...", "language": "...", "sections": []}}`  
**Trace:**  
1. `validatePdfWord` ‚Üí `sections.length === 0` ‚Üí `throw new Error('pdf_word.sections is missing or empty')`  
2. Retry + error  
**Result:** ‚úÖ Pass

### SUM-21: User cancels during file parsing
**Input:** User taps Cancel while file is being parsed  
**Trace:**  
1. `handleCancel()` ‚Üí `cancelledRef.current = true` ‚Üí `navigation.goBack()`  
2. `runSummarization`:  
   a. `parseUploadedFile` still running (async)  
   b. After parse completes: `if (cancelledRef.current) return` ‚Üí exits  
3. No further processing, no error  
**Result:** ‚úÖ Pass

### SUM-22: User cancels during AI call
**Input:** User taps Cancel while AI is processing  
**Trace:**  
1. `cancelledRef.current = true`  
2. `summarizeDocument` is still running (fetch in progress)  
3. Note: the abort controller is INSIDE `callLongcatAPI`, not accessible from cancel  
4. The fetch continues but after completion: `if (cancelledRef.current) return`  
5. Navigation already went back ‚Äî no further action  
6. Token usage still recorded (wasted tokens)  
**Result:** ‚ö†Ô∏è Minor ‚Äî tokens wasted on cancelled request, but no crash

### SUM-23: Network timeout during AI call
**Input:** Network goes offline after starting  
**Trace:**  
1. `callLongcatAPI` ‚Üí `setTimeout(() => controller.abort(), 30000)` ‚Üí 30s timeout  
2. fetch aborted after 30s ‚Üí AbortError  
3. Attempt 2: same timeout ‚Üí same error  
4. After 2 attempts: `"Failed to generate content after 2 attempts. Last error: The operation was aborted."`  
5. Alert shown with retry option  
**Result:** ‚úÖ Pass

### SUM-24: Summarize with Arabic output language
**Input:** English DOCX, output language="Arabic"  
**Trace:**  
1. File parsed ‚Üí English text  
2. `summarizeDocument(content, "Arabic", fileName)` ‚Üí prompt says "Output Language: Arabic"  
3. AI returns Arabic text in JSON  
4. Editor shows Arabic content  
5. On generate: PDF uses Arabic font (langNameToCode["arabic"] = 'ar' ‚úì)  
6. Word: isRTL = true ‚úì  
7. PPT: isRTL = true ‚úì but alignment hardcoded (known bug)  
**Result:** ‚úÖ Pass (except known PPT alignment bug)

### SUM-25: Summarize with Thai output language
**Input:** English DOCX, output language="Thai"  
**Trace:**  
1. AI returns Thai text  
2. Editor shows Thai content (React Native renders Thai fine)  
3. On generate: **PDF broken** (BUG GEN-BUG-1 ‚Äî Thai font not loaded)  
4. Word: Thai text in Calibri ‚Äî may not render perfectly but basic support exists  
5. Excel: Thai text as string values ‚Äî rendered by host app's font  
**Result:** ‚ö†Ô∏è PDF broken due to GEN-BUG-1

### SUM-26: Very short document (single sentence)
**Input:** TXT file: "The quick brown fox jumps over the lazy dog."  
**Trace:**  
1. Content = "The quick brown fox..." (45 chars)  
2. Content > 2 chars ‚úì, no truncation  
3. Summarization prompt: "Generate sections based on content length: for short documents (under 100 words), 1-2 sections is fine"  
4. AI returns 1-2 sections ‚Üí validates ‚Üí Editor opens  
**Result:** ‚úÖ Pass

### SUM-27: Document with HTML-like content
**Input:** TXT file containing `<h1>Title</h1><p>Paragraph</p>`  
**Trace:**  
1. `readAsStringAsync(uri, UTF8)` ‚Üí raw text including HTML tags  
2. No HTML stripping for .txt files ‚Äî HTML tags passed to AI as-is  
3. AI may or may not interpret HTML correctly  
**Result:** ‚úÖ Pass (no crash, AI handles it reasonably)

### SUM-28: RTF file upload
**Input:** Upload "document.rtf"  
**Trace:**  
1. `getFileType("document.rtf")` = 'rtf'  
2. `readAsStringAsync(uri, UTF8)` ‚Üí raw RTF content  
3. `stripRtf(raw)` ‚Üí removes font tables, color tables, control words, braces  
4. Converts `\par` to `\n`, `\'XX` to characters  
5. Clean text extracted  
6. Content validated ‚Üí AI processes  
**Result:** ‚úÖ Pass

### SUM-29: RTF file with complex formatting
**Input:** RTF with nested groups `{\b bold {\i bold-italic}}`  
**Trace:**  
1. `stripRtf`: removes control words `\b`, `\i` via regex `\\[a-z]+(-?\d+)?\s?`  
2. Removes `{` and `}` braces  
3. Result: "bold bold-italic"  
4. Text structure intact  
**Result:** ‚úÖ Pass

### SUM-30: File with Unicode BOM
**Input:** TXT file with UTF-8 BOM (0xEF 0xBB 0xBF) at start  
**Trace:**  
1. `readAsStringAsync(uri, UTF8)` ‚Üí Expo/RN handles BOM correctly  
2. Content starts with BOM character (if not stripped by Expo)  
3. BOM is invisible whitespace ‚Äî doesn't affect AI processing  
**Result:** ‚úÖ Pass

### SUM-31: Summarize then generate PDF in same language
**Input:** Summarize English DOCX ‚Üí edit ‚Üí generate all formats  
**Trace:**  
1. Full pipeline: parse ‚Üí summarize ‚Üí Editor ‚Üí generate  
2. Editor topic = "Summary: report.docx"  
3. `sanitizeTopic("Summary: report.docx")` ‚Üí "summary reportdocx" (`:` and `.` stripped)  
4. Files named correctly  
**Result:** ‚úÖ Pass

### SUM-32: XLSX with multiple sheets
**Input:** XLSX with 3 worksheets  
**Trace:**  
1. `parseXlsx`: finds sheet1.xml, sheet2.xml, sheet3.xml  
2. Each parsed with shared strings  
3. Content = "[Sheet 1]\n...\n\n[Sheet 2]\n...\n\n[Sheet 3]\n..."  
4. All sheet data sent to AI  
**Result:** ‚úÖ Pass

### SUM-33: XLSX with cell references (formulas)
**Input:** XLSX with `=SUM(A1:A5)` formula cells  
**Trace:**  
1. Formula cells: `<c>` element type is NOT `t="s"` (shared string)  
2. `<v>` contains calculated value (e.g., "50")  
3. `isShared = false` ‚Üí reads `valueMatch[1]` = "50" (the computed value)  
4. Formula result extracted, not the formula itself  
**Result:** ‚úÖ Pass

### SUM-34: File picker cancellation
**Input:** User opens picker then cancels  
**Trace:**  
1. `DocumentPicker.getDocumentAsync()` ‚Üí result.canceled = true  
2. `if (!result.canceled && result.assets...)` ‚Üí false ‚Üí `setUploadedFile` not called  
3. `uploadedFile` remains null  
4. If user taps Summarize: `!uploadedFile || uploadedFile.canceled` ‚Üí true ‚Üí Alert  
**Result:** ‚úÖ Pass

### SUM-35: Re-upload different file without clearing first
**Input:** Upload file A, then upload file B  
**Trace:**  
1. Upload A: `setUploadedFile(resultA)` ‚Üí state = resultA  
2. Upload B: `setUploadedFile(resultB)` ‚Üí state = resultB (overrides A)  
3. Old cached file A remains on disk (no cleanup)  
4. UI shows file B name correctly  
5. Summarize uses file B  
**Result:** ‚ö†Ô∏è Minor ‚Äî old cache file not cleaned up (known low-priority issue)

### SUM-36: Output language differs from document language
**Input:** Upload Chinese DOCX, output language="English"  
**Trace:**  
1. `parseDocx` extracts Chinese text  
2. Prompt: "Output Language: English" + Document Content: Chinese text  
3. AI reads Chinese and outputs English summary  
4. Editor shows English content  
5. Generation: English text ‚Üí Helvetica ‚úì  
**Result:** ‚úÖ Pass

### SUM-37: Markdown (.md) file upload
**Input:** Upload "README.md"  
**Trace:**  
1. `getFileType("README.md")` ‚Üí checks extension 'md' ‚Üí `typeMap['md'] = 'txt'`  
2. Read as UTF-8 text ‚Üí markdown syntax included in content  
3. AI processes markdown (headings `#`, bullets `- `, etc.)  
4. AI should extract structure from markdown reasonably  
**Result:** ‚úÖ Pass

### SUM-38: DocumentPicker permission denied
**Input:** User denies storage permission on Android  
**Trace:**  
1. `DocumentPicker.getDocumentAsync()` ‚Üí throws error  
2. Caught: `Alert.alert(t('alert_error'), t('alert_file_pick_failed'))`  
**Result:** ‚úÖ Pass

### SUM-39: File larger than storage allows
**Input:** 500MB XLSX file  
**Trace:**  
1. `copyToCacheDirectory: true` ‚Üí Expo copies file to cache  
2. `readAsStringAsync(uri, Base64)` ‚Üí may run out of memory  
3. If OOM: JavaScript error caught by try-catch ‚Üí error alert  
4. App might crash on very large files (RN heap limit ~1.5GB)  
**Result:** ‚ö†Ô∏è Extreme edge case ‚Äî large files may cause OOM crash (platform limitation)

### SUM-40: .doc file slipping through picker
**Input:** Legacy .doc file selected on Android with poor MIME filtering  
**Trace:**  
1. `getFileType("report.doc")` = 'docx' (mapped)  
2. `parseDocx(base64)` ‚Üí `JSZip.loadAsync(...)` ‚Üí .doc is OLE binary, not ZIP  
3. JSZip throws "Is not a valid zip file"  
4. Error caught: `Unable to read "report.doc": Is not a valid zip file. The file may be corrupted...`  
5. Alert shown  
**Result:** ‚úÖ Pass (error handled, but message could be clearer)

### SUM-41: File with only whitespace content
**Input:** TXT file with "   \n\t  \n  " (only whitespace)  
**Trace:**  
1. `readAsStringAsync` ‚Üí "   \n\t  \n  "  
2. `content.trim().length` = 0 ‚Üí `< 2` ‚Üí throws empty file error  
**Result:** ‚úÖ Pass

### SUM-42: AI response with code fences
**Input:** AI returns `\`\`\`json\n{...}\n\`\`\``  
**Trace:**  
1. `parseAIResponse(rawContent)`:  
   a. `cleaned = rawContent.trim()` ‚Üí starts with `\`\`\``  
   b. `cleaned.startsWith('\`\`\`')` ‚Üí true  
   c. `cleaned.replace(/^\`\`\`(?:json)?\s*\n?/, '')` ‚Üí strips opening  
   d. `.replace(/\n?\`\`\`\s*$/, '')` ‚Üí strips closing  
   e. JSON.parse succeeds  
**Result:** ‚úÖ Pass

### SUM-43: Language picker ‚Äî auto-detect selects device language
**Input:** Device language is Japanese, user doesn't change it  
**Trace:**  
1. `detectDeviceLanguage()` ‚Üí scans `SUPPORTED_LANGUAGES` for device locale  
2. If Japanese found ‚Üí returns Japanese option  
3. `[outputLanguage, setOutputLanguage]` initialized to Japanese  
4. User taps Summarize ‚Üí `language: "Japanese"` passed to processing  
**Result:** ‚úÖ Pass

### SUM-44: Language picker ‚Äî change language after file selection
**Input:** Select file, then change output language from English to Arabic  
**Trace:**  
1. File selected ‚Üí state = fileResult  
2. Language changed ‚Üí state = { ...arabicLang }  
3. Both states independent, no conflict  
4. On Summarize: file=selected, language=Arabic  
**Result:** ‚úÖ Pass

### SUM-45: UI state ‚Äî showLanguagePicker toggle
**Input:** Tap language picker open, then tap it again  
**Trace:**  
1. First tap: `setShowLanguagePicker(!showLanguagePicker)` ‚Üí true ‚Üí dropdown shown  
2. Second tap: `setShowLanguagePicker(!showLanguagePicker)` ‚Üí false ‚Üí dropdown hidden  
**Result:** ‚úÖ Pass

### SUM-46: DOCX with images (no text in body)
**Input:** DOCX containing only embedded images, no text  
**Trace:**  
1. `parseDocx` ‚Üí `stripXml(docXml)` ‚Üí only image elements ‚Üí XML stripped ‚Üí empty or near-empty text  
2. After strip: content might be just whitespace  
3. `content.trim().length < 2` ‚Üí throws empty file error  
**Result:** ‚úÖ Pass (correct error for image-only docs)

### SUM-47: Rate limiting ‚Äî Pexels API during generation
**Input:** After summarization ‚Üí Editor ‚Üí generate files with images  
**Trace:**  
1. `fetchImagesForKeywords` ‚Üí parallel fetch for all keywords  
2. If Pexels rate limits (HTTP 429) ‚Üí `searchPhoto` returns null  
3. Images Map empty or partial ‚Üí generators skip images  
4. No crash  
**Result:** ‚úÖ Pass

### SUM-48: Summarize processing ‚Äî progress bar accuracy
**Input:** Normal flow  
**Trace:**  
1. Step 0: setProgress(10) ‚Üí setProgress(25) ‚Äî file parse  
2. Step 1: setProgress(35) ‚Äî token check  
3. Step 2: setProgress(40) ‚Üí (AI running...) ‚Üí setProgress(85) ‚Äî AI complete  
4. Step 3: setProgress(100) ‚Äî navigate  
5. Progress jumps: 10‚Üí25‚Üí35‚Üí40‚Üí85‚Üí100 ‚Äî big gap from 40 to 85 during AI call  
**Result:** ‚ö†Ô∏è Minor UX ‚Äî progress bar doesn't update during AI call (stays at 40%)

### SUM-49: Summarize ‚Üí Editor ‚Üí change language ‚Üí generate
**Input:** Summarize English file ‚Üí Editor opens with English ‚Üí user cannot change language in Editor  
**Trace:**  
1. Editor receives `language` from route params ‚Äî it's read-only  
2. Editor has no language picker  
3. User can edit text but language used for generation is fixed  
4. If user writes Arabic text manually in the English editor, Word/PDF use English settings  
5. RTL detection would fail for manually-entered Arabic in "English" mode  
**Result:** ‚ö†Ô∏è Minor UX ‚Äî can't change output language in Editor

### SUM-50: Summarize with extremely long filename
**Input:** File name with 500 characters  
**Trace:**  
1. `uploadedFileName` = "very_long_name_...500chars..."  
2. Processing screen displays: `üìÑ {uploadedFileName}` ‚Äî may overflow UI  
3. `topic = \`Summary: ${uploadedFileName}\`` ‚Üí very long topic  
4. `sanitizeTopic(topic)` ‚Üí `.substring(0, 40)` ‚Äî truncated safely  
5. File generation works fine  
**Result:** ‚úÖ Pass (UI may overflow but no crash)

---

## PART 3: TRANSLATION SCENARIOS (TRANS-1 through TRANS-50)

### TRANS-1: Basic DOCX translation ‚Äî English to Spanish
**Input:** "report.docx", source="English", target="Spanish"  
**Trace:**  
1. TranslateScreen: file picked, source=English, target=Spanish  
2. `sourceLanguage.code !== targetLanguage.code` ‚Üí 'en' !== 'es' ‚Üí OK ‚úì  
3. Navigate to TranslateProcessing  
4. `parseUploadedFile(uri, fileName)` ‚Üí DOCX parsed successfully  
5. `canMakeRequest()` ‚Üí true  
6. `translateDocument(content, "English", "Spanish", fileName)` ‚Üí builds translation prompt  
7. Prompt: "Translate...from English to Spanish" + document content  
8. AI returns Spanish JSON ‚Üí validates ‚Üí Editor  
9. `topic = "report.docx ‚Üí Spanish"`  
10. `language = "Spanish"` ‚Üí used for all generators (correct language context)  
**Result:** ‚úÖ Pass

### TRANS-2: Same language selected ‚Äî validation
**Input:** source="English", target="English"  
**Trace:**  
1. `handleTranslate()`: `sourceLanguage.code === targetLanguage.code` ‚Üí 'en' === 'en' ‚Üí true  
2. `Alert.alert(t('alert_same_language_title'), t('alert_same_language_msg'))`  
3. Navigation blocked  
**Result:** ‚úÖ Pass

### TRANS-3: Swap languages button
**Input:** source=English, target=Arabic ‚Üí tap swap  
**Trace:**  
1. `handleSwapLanguages()`: `temp = sourceLanguage` (English)  
2. `setSourceLanguage(targetLanguage)` ‚Üí Arabic  
3. `setTargetLanguage(temp)` ‚Üí English  
4. Now source=Arabic, target=English  
**Result:** ‚úÖ Pass

### TRANS-4: No file selected ‚Äî validation
**Input:** User taps Translate without selecting file  
**Trace:**  
1. `uploadedFile` is null  
2. `!uploadedFile || uploadedFile.canceled` ‚Üí true  
3. Alert: "File required" message  
**Result:** ‚úÖ Pass

### TRANS-5: Translate to Arabic (RTL language)
**Input:** English DOCX ‚Üí Arabic  
**Trace:**  
1. AI returns Arabic text  
2. `language = "Arabic"` passed to Editor  
3. On generate:  
   - PDF: `hasNonLatinText` ‚Üí true ‚Üí Arabic font loaded (langNameToCode['arabic']='ar') ‚úì  
   - Word: isRTL = true, bidirectional flags set ‚úì  
   - PPT: rtlMode = true ‚úì (but align bug)  
**Result:** ‚úÖ Pass (except known PPT align bug)

### TRANS-6: Translate to Thai ‚Üê **BUG**
**Input:** English DOCX ‚Üí Thai  
**Trace:**  
1. AI returns Thai text  
2. On generate: PDF font loading fails for Thai (BUG GEN-BUG-1)  
3. All Thai text in PDF ‚Üí `?????`  
**Result:** ‚ùå **PDF broken for Thai (same BUG GEN-BUG-1)**

### TRANS-7: Translate to Bengali ‚Üê **BUG**
**Input:** English DOCX ‚Üí Bengali  
**Trace:** Same as TRANS-6. Bengali font not loaded. PDF broken.  
**Result:** ‚ùå **BUG GEN-BUG-1**

### TRANS-8: Translate to Hebrew ‚Üê **BUG**
**Input:** English DOCX ‚Üí Hebrew  
**Trace:**  
1. PDF: font loading fails (langNameToCode missing 'hebrew')  
2. Word: isRTL = true ('hebrew' in rtlLanguages) ‚Üí RTL flags set ‚úì  
3. PPT: not in rtlLanguages? Let me check... `rtlLanguages = ['arabic', 'hebrew', 'persian', 'farsi', 'urdu']` ‚Üí **yes, 'hebrew' IS in the list** ‚úì  
4. PDF broken, Word+PPT OK for RTL  
**Result:** ‚ùå **PDF broken for Hebrew (BUG GEN-BUG-1)**

### TRANS-9: Large file ‚Äî content truncation ‚Üê **BUG**
**Input:** Large DOCX (25K chars), translate English‚ÜíFrench  
**Trace:**  
1. `parseUploadedFile` ‚Üí content truncated to 15K + `[Content truncated...]`  
2. `wasTruncated = true`  
3. TranslateProcessingScreen: **never checks `wasTruncated`**  
4. AI translates only first ~15K chars, rest lost  
5. User not informed of truncation  
**Result:** ‚ùå **BUG TRANS-BUG-1: Truncation not communicated**

### TRANS-10: Translate with network error
**Input:** WiFi drops during AI call  
**Trace:**  
1. `callLongcatAPI` ‚Üí fetch fails ‚Üí retries  
2. After 2 retries ‚Üí error thrown  
3. `TranslateProcessingScreen` catch ‚Üí Alert with "Try Again" / "Go Back"  
**Result:** ‚úÖ Pass

### TRANS-11: User cancels during translation
**Input:** User taps Cancel during AI processing  
**Trace:**  
1. `cancelledRef.current = true` ‚Üí `navigation.goBack()`  
2. `runTranslation` continues async but checks `cancelledRef.current` after each step ‚Üí returns  
3. No navigation occurs (user already went back)  
**Result:** ‚úÖ Pass

### TRANS-12: Translate TXT file
**Input:** "notes.txt" English ‚Üí German  
**Trace:**  
1. `getFileType("notes.txt")` = 'txt'  
2. `readAsStringAsync(uri, UTF8)` ‚Üí text  
3. AI translates to German  
**Result:** ‚úÖ Pass

### TRANS-13: Translate XLSX file
**Input:** "data.xlsx" English ‚Üí Chinese  
**Trace:**  
1. `parseXlsx` extracts tabular text with `|` separators  
2. AI receives: "[Sheet 1]\nName | Age | City\nJohn | 25 | NYC..."  
3. AI translates column contents: "ÂßìÂêç | Âπ¥ÈæÑ | ÂüéÂ∏Ç\nÁ∫¶Áø∞ | 25 | Á∫ΩÁ∫¶..."  
4. Editor shows Chinese content  
5. PDF: Chinese font loaded (langNameToCode['chinese']='zh') ‚úì  
**Result:** ‚úÖ Pass

### TRANS-14: Translate PPTX with speaker notes
**Input:** English PPTX ‚Üí Japanese  
**Trace:**  
1. `parsePptx` extracts slides + speaker notes  
2. All text sent to AI with `[Slide N]` and `[Speaker Notes]` markers  
3. AI translates everything  
4. Note: speaker notes are translated but output is standard section format (notes not preserved as notes)  
**Result:** ‚úÖ Pass (content correct, but notes not specifically marked in output)

### TRANS-15: Translate RTF file
**Input:** "document.rtf" English ‚Üí French  
**Trace:**  
1. `getFileType("document.rtf")` = 'rtf'  
2. `stripRtf(raw)` extracts plain text  
3. AI translates to French  
**Result:** ‚úÖ Pass

### TRANS-16: Translate from Arabic to English (RTL ‚Üí LTR)
**Input:** Arabic DOCX ‚Üí English  
**Trace:**  
1. File parsed ‚Üí Arabic text extracted  
2. AI translates to English  
3. `language = "English"` ‚Üí used for generation  
4. PDF: `hasNonLatinText("The impact of...")` ‚Üí false ‚Üí Helvetica ‚úì  
5. Word: isRTL for "English" ‚Üí false ‚úì (no RTL)  
**Result:** ‚úÖ Pass

### TRANS-17: Token limit check ‚Äî both layers
**Input:** User has 100 tokens remaining (close to limit)  
**Trace:**  
1. TranslateProcessingScreen: `canMakeRequest()` ‚Üí true (100 > 0)  
2. `callLongcatAPI` ‚Üí `canMakeRequest()` ‚Üí true  
3. API call made, response received  
4. `recordTokenUsage(500)` ‚Üí remaining = -400 (over limit)  
5. Next request will be blocked  
**Result:** ‚úÖ Pass (current request goes through, next one blocked)

### TRANS-18: AI loses sections during translation
**Input:** English file with 5 well-defined sections ‚Üí translate to Arabic  
**Trace:**  
1. Original text has 5 sections  
2. AI returns only 3 sections (summarized during translation)  
3. `parseAIResponse` validates: `sections.length > 0` ‚Üí 3 > 0 ‚Üí passes  
4. No check that section count matches original  
5. User lost 2 sections without knowing  
6. Translation prompt says "Do NOT add new content or remove existing sections" but AI may not comply  
**Result:** ‚ö†Ô∏è Known issue ‚Äî AI may reduce sections (can't be fixed in code, only in prompts)

### TRANS-19: Translate direction display
**Input:** English ‚Üí Arabic  
**Trace:**  
1. TranslateProcessingScreen shows: `t('trans_processing_direction', { source: "English", target: "Arabic" })`  
2. Displays: "English ‚Üí Arabic" ‚úì  
**Result:** ‚úÖ Pass

### TRANS-20: Both language pickers open simultaneously
**Input:** User taps source picker then immediately taps target picker  
**Trace:**  
1. Source picker tap: `setShowSourcePicker(!showSourcePicker); setShowTargetPicker(false)`  
2. Source picker opens, target closes  
3. Target picker tap: `setShowTargetPicker(!showTargetPicker); setShowSourcePicker(false)`  
4. Target picker opens, source closes  
5. Only one picker visible at a time ‚úì  
**Result:** ‚úÖ Pass

### TRANS-21: Translate CSV file
**Input:** "data.csv" English ‚Üí Spanish  
**Trace:**  
1. `getFileType("data.csv")` = 'csv'  
2. `readAsStringAsync(uri, UTF8)` ‚Üí raw CSV text  
3. AI receives CSV format, translates content  
**Result:** ‚úÖ Pass

### TRANS-22: Translate to Greek ‚Üê **BUG**
**Input:** English DOCX ‚Üí Greek  
**Trace:**  
1. AI returns Greek text  
2. PDF: `hasNonLatinText(greekText)` ‚Üí Greek chars (Œë-œâ, 0x0391-0x03C9) > 0xFF ‚Üí true  
3. `langNameToCode["greek"]` = undefined ‚Üí code = "greek" ‚Üí font not found  
4. Falls back to Helvetica ‚Üí `sanitizeForWinAnsi` replaces Greek chars with `?`  
5. **PDF completely broken for Greek**  
**Result:** ‚ùå **BUG GEN-BUG-1 (Greek)**

### TRANS-23: Translate to Ukrainian ‚Üê **BUG**
**Input:** English DOCX ‚Üí Ukrainian  
**Trace:** Same as TRANS-22. Ukrainian Cyrillic not in langNameToCode ‚Üí `?????` in PDF.  
**Result:** ‚ùå **BUG GEN-BUG-1 (Ukrainian)**

### TRANS-24: Translate to Vietnamese ‚Üê **BUG**
**Input:** English DOCX ‚Üí Vietnamese  
**Trace:** Vietnamese diacriticals (·∫ø, ·ªï, etc.) > 0xFF ‚Üí flagged non-Latin ‚Üí font not found ‚Üí partially broken.  
**Result:** ‚ùå **BUG GEN-BUG-1 (Vietnamese)**

### TRANS-25: Translate empty file
**Input:** Upload empty.txt ‚Üí translate  
**Trace:**  
1. `parseUploadedFile` ‚Üí `content.trim().length < 2` ‚Üí throws  
2. TranslateProcessingScreen catches ‚Üí Alert  
**Result:** ‚úÖ Pass

### TRANS-26: Translate corrupt XLSX
**Input:** Renamed JPEG as "data.xlsx"  
**Trace:**  
1. `parseXlsx(base64)` ‚Üí JSZip.loadAsync ‚Üí "Is not a valid zip file"  
2. Error caught ‚Üí Alert  
**Result:** ‚úÖ Pass

### TRANS-27: Translate file with special Unicode chars
**Input:** TXT with emojis üéâüåçüî•, translate to Japanese  
**Trace:**  
1. Text content includes emojis ‚Üí sent to AI  
2. AI translates text, may preserve or ignore emojis  
3. Generated files: emojis in PDF (custom Japanese font) ‚Üí CJK range doesn't include emojis  
4. `sanitizeForWinAnsi` ‚Üí emojis become `?` (if Latin mode) OR font might not have emoji glyphs  
**Result:** ‚ö†Ô∏è Minor ‚Äî emojis may not render in PDF regardless of font

### TRANS-28: Translate to Russian (Cyrillic)
**Input:** English DOCX ‚Üí Russian  
**Trace:**  
1. `langNameToCode["russian"]` = 'ru' ‚úì  
2. `LANGUAGE_TO_FONT['ru']` = 'latin' ‚Üí Noto Sans (includes Cyrillic) ‚Üí font loaded  
3. Russian text renders correctly in PDF  
**Result:** ‚úÖ Pass

### TRANS-29: Translate to Turkish
**Input:** English DOCX ‚Üí Turkish  
**Trace:**  
1. `langNameToCode["turkish"]` = 'tr' ‚úì  
2. Turkish special chars (ƒ∞, ≈ü, ƒü, √ß, √∂, √º) ‚Üí Noto Sans Latin ‚Üí renders ‚úì  
**Result:** ‚úÖ Pass

### TRANS-30: Translate to Urdu (RTL)
**Input:** English DOCX ‚Üí Urdu  
**Trace:**  
1. `langNameToCode["urdu"]` = 'ur' ‚Üí `LANGUAGE_TO_FONT['ur']` = 'arabic' ‚Üí Arabic font ‚Üí ‚úì  
2. Word: isRTL = true ('urdu' in rtlLanguages) ‚úì  
3. PPT: isRTL = true ‚úì  
**Result:** ‚úÖ Pass

### TRANS-31: Translate between non-English languages
**Input:** Arabic DOCX ‚Üí Chinese  
**Trace:**  
1. Arabic text extracted from DOCX  
2. Prompt: "Translate from Arabic to Chinese" + Arabic content  
3. AI returns Chinese output  
4. `language = "Chinese"` ‚Üí PDF uses Chinese font ‚úì  
5. Word: isRTL for Chinese ‚Üí false (correct) ‚úì  
**Result:** ‚úÖ Pass

### TRANS-32: Translate file with tab-separated values
**Input:** TXT file with tab-separated data  
**Trace:**  
1. `readAsStringAsync` ‚Üí text with tabs  
2. AI receives tabular data, translates content cells  
3. Output structured as sections  
**Result:** ‚úÖ Pass

### TRANS-33: Translation processing ‚Äî step display
**Input:** Normal translation flow  
**Trace:**  
1. STEPS_KEYS = ['trans_processing_step_0', ..., 'trans_processing_step_3']  
2. Each step renders with dot indicators (gray/green/blue)  
3. Current step highlighted, previous steps marked green  
4. Progress bar: 10‚Üí25‚Üí35‚Üí40‚Üí85‚Üí100  
**Result:** ‚úÖ Pass

### TRANS-34: File name in result topic
**Input:** fileName="quarterly_report.docx", target="French"  
**Trace:**  
1. `topic = "quarterly_report.docx ‚Üí French"`  
2. `sanitizeTopic("quarterly_report.docx ‚Üí French")` ‚Üí arrow char stripped ‚Üí "quarterly_reportdocx  french" ‚Üí underscores ‚Üí "quarterly_reportdocx__french" ‚Üí substring(0,40) ‚Üí OK  
3. Files named with sanitized topic  
**Result:** ‚úÖ Pass

### TRANS-35: Translate then edit ‚Äî add new section
**Input:** After translation ‚Üí Editor ‚Üí user adds new section  
**Trace:**  
1. `addSection()` creates new section with i18n default text  
2. New slide added at matching index  
3. `sections.length` increases  
4. On generate: new section included in all formats  
**Result:** ‚úÖ Pass

### TRANS-36: Translate then edit ‚Äî delete all but one section
**Input:** Translation returns 4 sections ‚Üí user deletes 3  
**Trace:**  
1. `removeSection` checks `sections.length <= 1` ‚Üí blocks last deletion ‚úì  
2. User can delete down to 1 section  
3. Generation works with 1 section  
**Result:** ‚úÖ Pass

### TRANS-37: Translate then edit ‚Äî AI improve section
**Input:** In Editor, user taps AI improve on section 0  
**Trace:**  
1. `handleAIAction(0, 'improve')` ‚Üí `aiEditSection('improve', section, language, title)`  
2. `canMakeRequest()` checked ‚Üí OK  
3. API call with section content + improvement instructions  
4. Result: updated heading, paragraph, bullets  
5. `setSections` updated at index 0  
6. `setSlides` updated at index 0 (synced)  
7. `recordTokenUsage` tracks tokens  
**Result:** ‚úÖ Pass

### TRANS-38: Translate then edit ‚Äî AI expand section
**Input:** AI expand on short section  
**Trace:** Similar to TRANS-37. Expand instruction says "Make paragraph at least 2x longer. Add 2-3 more bullet points."  
AI returns expanded content ‚Üí section updated.  
**Result:** ‚úÖ Pass

### TRANS-39: Translate then edit ‚Äî AI shorten section
**Input:** AI shorten on long section  
**Trace:** Shorten instruction: "Reduce paragraph to 2-3 sentences max. Keep only top 3 bullet points."  
AI returns condensed content ‚Üí section updated.  
**Result:** ‚úÖ Pass

### TRANS-40: Translate then edit ‚Äî AI regenerate section
**Input:** AI regenerate section  
**Trace:**  
1. `temperature: 0.9` (higher for regenerate vs 0.6 for others)  
2. AI completely rewrites section  
3. Updated in both sections and slides states  
**Result:** ‚úÖ Pass

### TRANS-41: AI section edit ‚Äî parsing failure
**Input:** AI returns non-JSON for section edit  
**Trace:**  
1. `aiEditSection` ‚Üí API returns plain text  
2. `JSON.parse(cleaned)` ‚Üí throws SyntaxError  
3. Error propagates to `handleAIAction` catch:  
   `Alert.alert(t('alert_ai_error_title'), msg)`  
4. Section unchanged  
**Result:** ‚úÖ Pass

### TRANS-42: AI section edit ‚Äî empty/missing fields
**Input:** AI returns `{"heading": "", "paragraph": "...", "bullets": []}`  
**Trace:**  
1. `parsed.heading` = "" ‚Üí `parsed.heading || section.heading` ‚Üí falls back to original heading  
2. `parsed.bullets` = [] ‚Üí `Array.isArray([]) && [].length > 0` ‚Üí false ‚Üí falls back to original bullets  
3. Only paragraph updated  
**Result:** ‚úÖ Pass

### TRANS-43: DOCX with rich formatting (tables, shapes)
**Input:** DOCX containing tables  
**Trace:**  
1. `parseDocx` ‚Üí `stripXml` removes all XML tags  
2. Table cell content extracted as text (structure lost)  
3. AI receives flattened text without table structure  
4. Translation may lose table context  
**Result:** ‚ö†Ô∏è Minor ‚Äî table structure lost during parsing (inherent limitation)

### TRANS-44: XLSX with merged cells
**Input:** XLSX with merged cells in data  
**Trace:**  
1. `parseXlsx` ‚Üí `<c>` cells extracted from `<row>` elements  
2. Merged cells: only first cell has `<v>` value, others empty  
3. Not all cells extracted for merged ranges  
4. Some data may be missing in parsed text  
**Result:** ‚ö†Ô∏è Minor ‚Äî merged cell data partially lost (inherent limitation)

### TRANS-45: Default language selection
**Input:** Device locale is 'de' (German)  
**Trace:**  
1. `detectDeviceLanguage()` ‚Üí finds German in SUPPORTED_LANGUAGES  
2. `sourceLanguage` = German  
3. `targetLanguage` = first language that's not German  
4. `SUPPORTED_LANGUAGES.find(l => l.code !== 'de')` ‚Üí English (likely first in list)  
5. Default: German ‚Üí English  
**Result:** ‚úÖ Pass

### TRANS-46: Language with unsupported device locale
**Input:** Device locale is 'sw' (Swahili) ‚Äî not in SUPPORTED_LANGUAGES  
**Trace:**  
1. `detectDeviceLanguage()` ‚Üí no match ‚Üí falls back to English  
2. `sourceLanguage` = English  
**Result:** ‚úÖ Pass

### TRANS-47: Translate result ‚Üí download ‚Üí SAF on Android
**Input:** Generated files ‚Üí user taps Download  
**Trace:**  
1. ResultScreen: `handleDownload(file)`  
2. `FileSystem.getInfoAsync(file.path)` ‚Üí exists ‚úì  
3. `StorageAccessFramework.requestDirectoryPermissionsAsync()` ‚Üí user grants  
4. `readAsStringAsync(file.path, Base64)` ‚Üí base64 content  
5. `createFileAsync(dirUri, file.name, mimeType)` ‚Üí creates file in chosen dir  
6. `writeAsStringAsync(newUri, base64, Base64)` ‚Üí writes file  
7. Success alert  
**Result:** ‚úÖ Pass

### TRANS-48: Download ‚Äî file not found (deleted from cache)
**Input:** User navigates back, cache cleared, comes back to Result  
**Trace:**  
1. `FileSystem.getInfoAsync(file.path)` ‚Üí `exists: false`  
2. `Alert.alert(t('alert_error'), t('alert_file_not_found'))`  
**Result:** ‚úÖ Pass

### TRANS-49: Share ‚Äî Sharing not available
**Input:** Device doesn't support sharing  
**Trace:**  
1. `Sharing.isAvailableAsync()` ‚Üí false  
2. `Alert.alert(t('alert_sharing_not_available_title'), ...)`  
**Result:** ‚úÖ Pass

### TRANS-50: Translate long DOCX and generate all formats
**Input:** 14000 char DOCX, English ‚Üí Korean  
**Trace:**  
1. Content not truncated (14000 < 15000) ‚úì  
2. `translateDocument(content, "English", "Korean", ...)` ‚Üí large prompt ~16K tokens  
3. API `max_tokens: 2048` for response ‚Üí may be insufficient for 14K char translation  
4. AI returns truncated response with fewer sections than original  
5. `parseAIResponse` validates basic structure ‚Üí passes  
6. Editor shows partial translation  
7. PDF: `langNameToCode["korean"]` = 'ko' ‚Üí Korean font loaded ‚úì  
8. All formats generated  
**Result:** ‚ö†Ô∏è AI response may be truncated (max_tokens is 2048 for output), losing content

---

## COMPREHENSIVE BUG FIX PLAN

### Fix 1: PDF langNameToCode ‚Äî Add missing 6 languages
**File:** `src/generators/pdfGenerator.ts`  
**Action:** Add `thai: 'th', bengali: 'bn', hebrew: 'he', greek: 'el', vietnamese: 'vi', ukrainian: 'uk'` to `langNameToCode`  
**Impact:** Fixes PDFs for Thai, Bengali, Hebrew, Greek, Vietnamese, Ukrainian  

### Fix 2: sections.indexOf always returns -1
**File:** `src/screens/EditorScreen.tsx`  
**Action:** Track original index through filter/map chain  
**Impact:** PPT generation uses actual slide state  

### Fix 3: PDF section headings ‚Äî wrap instead of truncate
**File:** `src/generators/pdfGenerator.ts`  
**Action:** Use `wrapText()` for headings like paragraphs  
**Impact:** Long headings fully visible  

### Fix 4: PDF title page overflow
**File:** `src/generators/pdfGenerator.ts`  
**Action:** Clamp titleY to MAX(titleY, MARGIN)  
**Impact:** Very long titles stay within page bounds  

### Fix 5: Empty validSections validation
**File:** `src/screens/EditorScreen.tsx`  
**Action:** Check if validSections is empty, show Alert before generation  
**Impact:** Prevents generating empty documents  

### Fix 6: PPT RTL alignment
**File:** `src/generators/pptGenerator.ts`  
**Action:** Use `isRTL ? 'right' : 'left'` for title slide text  
**Impact:** Arabic/Hebrew PPT titles properly aligned  

### Fix 7: fontCacheService base64 padding
**File:** `src/services/fontCacheService.ts`  
**Action:** Fix `bitsCount` calculation in inline encoder  
**Impact:** Correct base64 encoding for cached fonts  

### Fix 8: Truncation warning for Summarize/Translate
**File:** `src/screens/SummarizeProcessingScreen.tsx` + `TranslateProcessingScreen.tsx`  
**Action:** Check `parsed.wasTruncated` and show Alert with option to continue  
**Impact:** Users informed when large files are truncated  
